{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from scipy.special import softmax\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "# MS: TODO comment out for now\n",
    "#import biomart\n",
    "\n",
    "import umap\n",
    "import pickle\n",
    "import scipy.spatial as sp\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "from scipy.spatial.distance import pdist,squareform\n",
    "from scipy.cluster import hierarchy\n",
    "\n",
    "import glob\n",
    "import torch\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NB_OUTPUT = 'output'\n",
    "os.makedirs(NB_OUTPUT, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f6f4448b567d429"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Goal = Attempt to recreate Fig. 2 of biorxiv manuscript"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "daadfaca98aa8f52"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Utility functions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3138b7dd674b6085"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\" code from Karin2024\n",
    "def run(self, x0, w, beta, dt=0.1, tmax=10):\n",
    "    x=x0.copy()\n",
    "    hist = []\n",
    "    for t in np.arange(0,tmax,dt):\n",
    "        hist.append(x.copy())\n",
    "        x+=dt*(np.matmul(self.Q.T,softmax(w+beta*np.matmul(self.XI,x)))-x)\n",
    "        \n",
    "    hist = np.array(hist)\n",
    "    return x,hist\n",
    "\"\"\"\n",
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "\n",
    "USE_SCIPY_INTEGRATOR = True # f False, use Euler integration (manual)\n",
    "\n",
    "\n",
    "def run_traj(f_of_txp, x0, params, t0=0.0, tmax=10.0, dt_max=0.1):\n",
    "    # TODO have local function for x_t+1 = foo(x_t) which is autograd-able\n",
    "    \n",
    "    # if scipy integrator  maybe writeup runge kutta\n",
    "    if USE_SCIPY_INTEGRATOR:\n",
    "        # https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.solve_ivp.html\n",
    "        # methods: RK45 [=default], Radau, ...\n",
    "        sol = solve_ivp(f_of_txp, [t0, tmax], x0, args=[params], method='RK45', dense_output=True)\n",
    "        #x_traj = sol.y.T\n",
    "        #times_traj = sol.t\n",
    "        \n",
    "        # now replace direct output with with dense_output\n",
    "        times_traj = np.arange(t0, tmax + dt_max, dt_max)    # size T\n",
    "        x_traj = sol.sol(times_traj).T                       # size T x N\n",
    "        \n",
    "    else: \n",
    "        # simple euler integration\n",
    "        times_traj = np.arange(t0, tmax + dt_max, dt_max)    # size T\n",
    "        x_traj = np.zeros((len(times_traj), x0.shape[0]))    # size T x N\n",
    "        \n",
    "        x_traj[0, :] = x0\n",
    "        for idx, tval in enumerate(times_traj[:-1]): \n",
    "            current_vel = f_of_txp(tval, x_traj[idx, :], params) \n",
    "            x_traj[idx+1, :] = x_traj[idx, :] + dt_max * current_vel\n",
    "    return x_traj, times_traj"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "823e15e8b4afc2b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Silly example testing the generalic trajectory function: \n",
    "## - launch particle, only force is gravity $d v_y / dt = -g$"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e7e0b36fa73a8a6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Note: keep signature of function fixed for now as x, t, p - state [dim N], times [scalar], params [dim p]\n",
    "# TODO jit all func, or torch for eventual Autodiff\n",
    "\n",
    "def dxdt_particle(t, x, params):\n",
    "    \"\"\"\n",
    "    # Throw a ball in R^2\n",
    "    # Three params: vx0, vy0, gravity\n",
    "    \"\"\"\n",
    "    vx0, vy0, g = params\n",
    "    \n",
    "    dxdt = np.zeros_like(x)\n",
    "    dxdt[0] = vx0\n",
    "    dxdt[1] = vy0 - g*t\n",
    "    return dxdt #np.array([dxdt, dydt])\n",
    "\n",
    "# sample call\n",
    "dxdt_particle(0, [10, 10], [1, 1, 9.8])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e32085715a46f202"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "solve_ivp(dxdt_particle, [0.0, 4.0], [10, 10], args=[(1, 1, 9.8)], method='Radau', dense_output=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d62c575406459d56"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x0 = np.array([10, 100])\n",
    "#x0 = [10, 100]\n",
    "params = [1, 10, 9.8]\n",
    "x_traj, times_traj = run_traj(dxdt_particle, x0, params, t0=0.0, tmax=2, dt_max=0.1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d0fffc9174af6e8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(2, 1, sharex=True)\n",
    "pltstyle = dict(linestyle='--', marker='o')\n",
    "axarr[0].plot(times_traj, x_traj[:,0], **pltstyle); axarr[0].set_title('x vs t') \n",
    "axarr[1].plot(times_traj, x_traj[:,1], **pltstyle); axarr[1].set_title('y vs t')\n",
    "plt.suptitle('Simple example: launch particle with gravity - euler method')\n",
    "plt.show(); plt.close('all')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88a7e728bd3ed3ab"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classic (quadratic) hopfield network with continuous variables $x \\in \\mathbb{R}^N$\n",
    "\n",
    "My suggested form\n",
    "### $\\frac{dx}{dt} = -x + \\textrm{tanh}(\\beta [Jx + b])$\n",
    "\n",
    "where \n",
    "\n",
    "- $\\beta=1/T$ is inverse temperature -- at zero temperature limit its digital (sign function)\n",
    "- $J=\\xi \\xi^T$ is defined by the $N \\times K$ matrix of cell types, with cell type $\\mu=1, ..., K$ indexing the cell types represented by columns of $\\xi$ \n",
    "- $b \\in \\mathbb{R}^N$ is an $N$ dimensional applied field on specific genes; we will reserve $w \\in \\mathbb{R}^K$ to denote an analogous forcing applied in the direction of the $K$ encoded cell types\n",
    "\n",
    "The form in Hopfield, 1984 (PNAS):\n",
    "### $\\frac{dx}{dt} = -x + J \\:\\textrm{tanh}(\\beta x) + b$\n",
    "\n",
    "#### Remark 1: on representations\n",
    "The main dynamics stated at the top are not unique. The nonlinearity can be applied before or after the linearity. Here is a general recipe for a recurrent dynamics in $\\mathbb^N$ combining an affine transform and a static elementwise nonlinearity $\\sigma(z)$:\n",
    "- Representation 1:  $dx/dt = -x + \\sigma(Ax + b)$\n",
    "- Representation 2:  $dy/dt = -y + A\\sigma(y) + b$\n",
    "\n",
    "I tend to prefer Option 1, but they are sometimes treated interchangeably in the literature. Consider specifically the linear change of variables $y=Ax+b$. When $A$ is invertible, the two representations are equivalent. Otherwise, the situation is more subtle: \n",
    "- Going from Rep (1) to Rep (2) works even when $A$ is not full rank. \n",
    "- However, if $A$ is not full rank, starting from Rep (2) one comes to $A\\: dx/dt = A (-x + \\sigma(Ax+b))$. Consider the thin SVD of $A$, corresponding to the first sum in $A= \\sum_{i=1}^p \\sigma_i u_i v_i^T + \\sum_{i=p+1}^N 0 \\cdot u_i v_i^T$, accounting for the $p<N$ non-zero singular values ($p = N$ would imply invertible). In matrix form $A=UDV^T$ with $U, V \\in \\mathbb{R}^{N \\times p}$. Left multiplying by the pseudoinverse for $U$ and inverse for $D$ gives the reduced dynamics for $m=V^T x$ in $p<N$ dimensions:  $dm/dt = -m + V^T \\:\\sigma(U D m + b)$ -- is it interesting that this $p$-dim dynamics is equivalent to the $N>p$ dim dynamics? \n",
    "\n",
    "I also tend to use the nonlinearity $\\sigma(z) = \\textrm{tanh}(\\beta z)$. This choice is inspired by the mean-spin flip update rule of the binary Ising model with (stochastic) Glauber dynamics. Combined with Option 1, it has a nice interpretation that any fixed point lies in or on the $\\pm 1$ hypercube ($\\equiv \\Omega_N$); more generally, note that $\\Omega_N$ is positively invariant for this choice of $\\sigma(z)$. To \"think outside the box\", one could consider alternative nonlinearities like $\\sigma(z)=\\textrm{ReLU}(z)$. \n",
    "\n",
    "#### Remark 2: Alternative RBM-like two-layer form see [Krotov and Hopfield, 2021, ICLR] (TODO q: when is it equivalent?) :\n",
    "- $\\tau_v\\: \\frac{dv}{dt} = -v + W_v \\,f(h) + b$\n",
    "- $\\tau_h\\: \\frac{dh}{dt} = -h + W_h \\,g(v) + w$\n",
    "\n",
    "Notation: \n",
    "\n",
    "- Let $W_v \\in \\mathbb{R}^{N \\times K}$ be a matrix of connections from \"hidden\" units $h \\in \\mathbb{R}^K$ to \"visible\" units $x \\in \\mathbb{R}^N$. Let $W_h \\in \\mathbb{R}^{K \\times N}$ denote reverse connections from the visible to the hidden units. The authors assume symmetric connections between the layers, i.e. $W_v=\\xi$ and $W_h=\\xi^T$. \n",
    "- $f:\\mathbb{R}^K \\rightarrow \\mathbb{R}^N$, $g:\\mathbb{R}^N \\rightarrow \\mathbb{R}^K$ are potentially nonlinear functions of a given neuron (e.g. $g_{i} \\equiv \\textrm{tanh}(v_{i})$  or the entire layer (e.g. in the case of $\\textrm{softmax}$). \n",
    "\n",
    "In the 2021 ICLR paper for classical quadratic HN they use \n",
    "- $f(h)=h \\:\\:$  i.e. linear\n",
    "- $g(v)=\\textrm{sgn}(v)\\approx \\textrm{tanh}(\\beta v)$\n",
    "- \n",
    "##### Comment on relative timescales for the two-layer dynamics\n",
    "If one timescale ($\\tau_v, \\tau_h$) is much faster (i.e. small $\\tau$), then the associated dynamics can be eliminated (treated as being at \"quasi-steady-state\"). In that case, the coupled dynamics can be viewed as a \"singular expansion\" of the uncoupled form. \n",
    "\n",
    "E.g., if $\\tau_h \\ll \\tau_v$, then $h(t) \\approx \\xi^T g(v) + w$ at all times (since any deviation will rapidly be corrected, relatively speaking).\n",
    "\n",
    "As a concrete example, consider the choice of $f$, $g$ above mapping to a classic hebbian Hopfield network. Assuming  $\\tau_h \\ll \\tau_x$ and making the QSS substitution gives the condensed dynamics $\\tau_v\\: dv/dt = -v + \\xi \\:\\textrm{tanh} \\left[ \\beta (\\xi^T v + w) \\right] + b$.\n",
    "\n",
    "#### Additional notes from recent [Krotov and Hopfield, 2021, ICLR]\n",
    "TODO...\n",
    "\n",
    "#### Refs:\n",
    "- [Krotov and Hopfield, 2021, ICLR](https://arxiv.org/pdf/2008.06996)\n",
    "- [Krotov and Hopfield, 2019, PNAS](https://www.pnas.org/doi/abs/10.1073/pnas.1820458116)\n",
    "\n",
    "  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6fe062da3496c120"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_xi_rolling_correlated(N, p=3):\n",
    "    \"\"\"\n",
    "    N: number of visible units\n",
    "    p: number of patterns (column vectors)\n",
    "    \"\"\"\n",
    "    assert N % p == 0\n",
    "    a = -1 * np.ones(N)\n",
    "    a[0:p] = 1\n",
    "    \n",
    "    xi = np.zeros((N, p))\n",
    "    for idx in range(p):\n",
    "        xi[:, idx] = np.roll(a, p * idx, axis=None)\n",
    "    return xi\n",
    "\n",
    "def build_xi_random_binary(N, p, seed=0):\n",
    "    \"\"\"\n",
    "    N: number of visible units\n",
    "    p: number of patterns (column vectors)\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    xi = 2*np.random.randint(2, size=(N,p)) - 1\n",
    "    return xi"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c3ffa0039e23f4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "N_rand, K_rand = 5000, 4\n",
    "xi_rand = build_xi_random_binary(N_rand, K_rand)\n",
    "print('Corr. matrix for K=%d random patterns in N=%d dims' % (K_rand, N_rand))\n",
    "print(xi_rand.T @ xi_rand / N_rand)\n",
    "\n",
    "print('\\nLow dim correlated example (N=%d, K=%d)' % (K_rand, N_rand))\n",
    "N_simple, K_simple = 9, 3\n",
    "xi_9_3_corr = build_xi_rolling_correlated(N_simple, p=K_simple)\n",
    "#print(xi_9_3_corr)\n",
    "print(xi_9_3_corr.T @ xi_9_3_corr / xi_9_3_corr.shape[0])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b34f27b9a2872fb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Note: keep signature of function fixed for now as x, t, p - state [dim N], times [scalar], params [dim p]\n",
    "# TODO jit all func, or torch for eventual Autodiff\n",
    "\n",
    "#@torch.jit\n",
    "def dxdt_HN_quadratic_hebb_A(t, x, params):\n",
    "    \"\"\"\n",
    "    - My preferred form: arises from mean spin flip rule for stochastic discrete updates\n",
    "    - This form works roughly as expected\n",
    "    \"\"\"\n",
    "    beta, xi = params\n",
    "    xi = xi / np.sqrt(xi.shape[0])  # local normalize\n",
    "    arg_of_sigma = xi @ xi.T @ x\n",
    "    dxdt = -x + np.tanh(beta * arg_of_sigma)\n",
    "    return dxdt\n",
    "\n",
    "def dxdt_HN_quadratic_hebb_B(t, x, params):\n",
    "    \"\"\"\n",
    "    This form is closer to Hopfield 1984\n",
    "    - Also Eq. (24) of K+H, 2021, ICLR \n",
    "    - See spurious minima when point in vicinity of pattern 0 is given small linear push towards other other patterns\n",
    "    \"\"\"\n",
    "    beta, xi = params\n",
    "    xi = xi / np.sqrt(xi.shape[0])  # local normalize\n",
    "    arg_of_sigma = x\n",
    "    dxdt = -x + xi @ xi.T @ np.tanh(beta * arg_of_sigma)\n",
    "    return dxdt\n",
    "\n",
    "def dxdt_HN_quadratic_hebb_C(t, x, params):\n",
    "    \"\"\"\n",
    "    Issues with this form, which arises from RBM-type interpretation  \n",
    "    - see Eq. (1) of K+H, 2021, ICLR \n",
    "    - try to match Sec 3.1 and App. B of K+H, 2021, ICLR \n",
    "    - TODO check implementation and issues...\n",
    "    \n",
    "    Here x is a dim N + dim K - coupled two-layer RBM style dynamics\n",
    "    \n",
    "    In the QSS limit of fast h dynamics, this reduces to the form in dxdt_HN_quadratic_hebb_B(...)\n",
    "    \"\"\"\n",
    "    beta, xi = params\n",
    "    dim_N, dim_K = xi.shape\n",
    "    xi = xi / np.sqrt(xi.shape[0])  # local normalize\n",
    "    \n",
    "    state_v = x[:dim_N]\n",
    "    state_h = x[dim_N:]\n",
    "    \n",
    "    f_mu_of_h = state_h                 # see Eq. (27)\n",
    "    g_i_of_v = np.tanh(beta * state_v)  # like sign function\n",
    "    \n",
    "    dxdt = np.zeros_like(x)    \n",
    "    \n",
    "    # v dynamics - N dim\n",
    "    dxdt[:dim_N] = -state_v + xi @ f_mu_of_h  # TODO add applied fields?\n",
    "    # v dynamics - K dim\n",
    "    dxdt[dim_N:] = -state_h + xi.T @ g_i_of_v \n",
    "    return dxdt\n",
    "\n",
    "\n",
    "def dxdt_HN_quadratic_hebb_D(t, x, params):\n",
    "    \"\"\"\n",
    "    Issues with this form, which arises from RBM-type interpretation  \n",
    "    - try to match Sec 3.1 and App. B of K+H, 2021, ICLR \n",
    "    Here x is dim K - integrate out the visible units, only slow hidden dynamics \n",
    "    - corresponds to h_mu variables; assume v(t) = xi.T f(h) + b at all times \n",
    "    Form is as below with tau and applied fields dropped: \n",
    "        dv/dt = -v + xi tanh beta (xi^T v + w) + b.\n",
    "    \"\"\"\n",
    "    beta, xi = params\n",
    "    dim_N, dim_K = xi.shape\n",
    "    #xi = xi / np.sqrt(dim_N)  # local normalize\n",
    "    \n",
    "    state_h = x\n",
    "    f_mu_of_h = state_h                 # see Eq. (27)\n",
    "\n",
    "    state_v = xi @ f_mu_of_h            # QSS assumption; omit +b (applied field, N dim)\n",
    "    g_i_of_v = np.tanh(beta * state_v)  # like sign function\n",
    "    \n",
    "    # h dynamics - K dim    \n",
    "    dhdt = -state_h + xi.T @ g_i_of_v / dim_N  # / np.sqrt(xi.shape[0])   # dx/dt = -x + xi.T tanh( xi @ h )\n",
    "\n",
    "    return dhdt\n",
    "\n",
    "# sample call\n",
    "local_beta = 10.0\n",
    "local_xi = xi_rand\n",
    "local_N, local_K = local_xi.shape\n",
    "params = (local_beta, local_xi)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9bc96c95f44e6d75"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get trajectories and plot the projection onto pattern subspace + norm of vector field\n",
    "\n",
    "Note: x is used as shorthand for state; it can mean: \n",
    "- just v (dim N); or \n",
    "- just h (dim K); or \n",
    "- v + h  (dim N+K)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7146b0102a30a6e9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "v0 = np.random.rand(local_N)\n",
    "\n",
    "h0 = local_xi.T @ v0 / local_N  # Option 1: target vector based on visible layer\n",
    "#h0 = np.zeros(local_K)           # Option 2: zero vector\n",
    "\n",
    "vh0 = np.concatenate((v0, h0))\n",
    "print('h0 (overlaps):', h0)\n",
    "print('norm of h0:', np.linalg.norm(h0))\n",
    "print(vh0.shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0edac983986cc33"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "methods_foo = [dxdt_HN_quadratic_hebb_A, dxdt_HN_quadratic_hebb_B, dxdt_HN_quadratic_hebb_C, dxdt_HN_quadratic_hebb_D]#, dxdt_HN_quadratic_hebb_D]\n",
    "n_methods = len(methods_foo)\n",
    "\n",
    "methods_str = ['(A - dim N)', '(B - dim N)', '(C - dim N+K)', '(D - dim K)']\n",
    "methods_x0 = [v0, v0, vh0, h0]\n",
    "methods_traj_x = [0] * n_methods\n",
    "methods_traj_t = [0] * n_methods\n",
    "\n",
    "for idx in range(n_methods):\n",
    "    print('Working on traj %d (%d total)...' % (idx, n_methods))\n",
    "    x_traj, times_traj = run_traj(methods_foo[idx], methods_x0[idx], params, t0=0.0, tmax=4, dt_max=0.1)\n",
    "    methods_traj_x[idx] = x_traj\n",
    "    methods_traj_t[idx] = times_traj"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46707820de7be0c0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#methods_foo[0](methods_traj_x[idx].T, 0, params)\n",
    "\n",
    "#fig, axarr = plt.subplots(3, 2, sharex=True, figsize=(8,9))\n",
    "fig, axarr = plt.subplots(n_methods, 2, sharex=True, figsize=(8, 3*n_methods))\n",
    "pltstyle = dict(linestyle='-', marker='o', markersize=3)\n",
    "pltstyle_h_mu = dict(linestyle='--', marker='^', markersize=6, markerfacecolor='None', alpha=0.75, zorder=10)\n",
    "\n",
    "for idx in range(n_methods):\n",
    "    if methods_traj_x[idx].shape[1] == local_K:\n",
    "        axarr[idx, 0].plot(methods_traj_x[idx],  **pltstyle_h_mu)  # in this case, we are plotting the hidden/memory variables directly\n",
    "    else:\n",
    "        axarr[idx, 0].plot(methods_traj_x[idx][:, :local_N] @ params[1] / local_N,  **pltstyle)\n",
    "        if methods_traj_x[idx].shape[1] == (local_N + local_K):\n",
    "            # also plot hidden dim directly...\n",
    "            cc = [line_obj.get_c() for line_obj in axarr[idx, 0].get_lines()]\n",
    "            axarr[idx, 0].set_prop_cycle('color', cc)\n",
    "            axarr[idx, 0].plot(methods_traj_x[idx][:, :local_N] @ params[1] / local_N,  **pltstyle_h_mu)\n",
    "    axarr[idx, 0].set_title('HN classic quadratic %s' % methods_str[idx])\n",
    "    axarr[idx, 0].axhline(0, linestyle='--', linewidth=2, c='k')\n",
    "    \n",
    "    dxdt_arr = methods_foo[idx](0, methods_traj_x[idx].T, params)\n",
    "    axarr[idx, 1].plot(np.linalg.norm(dxdt_arr, axis=0),  **pltstyle)\n",
    "    axarr[idx, 1].set_title('Norm of $dx/dt$ for %s' % methods_str[idx])\n",
    "    axarr[idx, 1].axhline(0, linestyle='--', linewidth=2, c='k')\n",
    "    \n",
    "axarr[-1, 0].set_xlabel('t')\n",
    "axarr[-1, 1].set_xlabel('t')\n",
    "plt.suptitle('Example: HN classic quadratic\\n' + r'Trajectory $N^{-1} \\xi^T x(t)$ from random IC (N=%d, K=%d)' % (local_N, local_K))\n",
    "plt.savefig(NB_OUTPUT + os.sep + 'HN-traj.pdf')\n",
    "plt.show(); plt.close('all')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "640ff9ab2b317f1a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Classic HN variants: Repeat but for non-random IC (in vicinity of pattern 0)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "510d5b8799fc7b41"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "coeffs_rand = np.random.normal(loc=0, scale=0.2, size=local_K)\n",
    "print(coeffs_rand)\n",
    "\n",
    "v0_near_pattern_0 = params[1][:, 0] + coeffs_rand @ params[1][:, :].T\n",
    "print('overlaps:', params[1].T @ v0_near_pattern_0 / local_N)\n",
    "\n",
    "h0 = local_xi.T @ v0_near_pattern_0 / local_N  # Option 1: target vector based on visible layer\n",
    "#h0 = np.zeros(local_K)           # Option 2: zero vector\n",
    "\n",
    "v0_near_pattern_0_attach_h0 = np.concatenate((v0_near_pattern_0, h0))\n",
    "print('h0 (overlaps):', h0)\n",
    "print('norm of h0:', np.linalg.norm(h0))\n",
    "print(v0_near_pattern_0_attach_h0.shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe190d9b411387b6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "methods_traj_x = [0] * n_methods\n",
    "methods_traj_t = [0] * n_methods\n",
    "methods_x0 = [v0_near_pattern_0, v0_near_pattern_0, v0_near_pattern_0_attach_h0, h0]\n",
    "\n",
    "for idx in range(n_methods):\n",
    "    x_traj, times_traj = run_traj(methods_foo[idx], methods_x0[idx], params, t0=0.0, tmax=4, dt_max=0.1)\n",
    "    methods_traj_x[idx] = x_traj\n",
    "    methods_traj_t[idx] = times_traj"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d116a4bb963012e8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#fig, axarr = plt.subplots(3, 2, sharex=True, figsize=(8,9))\n",
    "fig, axarr = plt.subplots(n_methods, 2, sharex=True, figsize=(8, 3*n_methods))\n",
    "pltstyle = dict(linestyle='-', marker='o', markersize=3)\n",
    "pltstyle_h_mu = dict(linestyle='--', marker='^', markersize=6, markerfacecolor='None', alpha=0.75, zorder=10)\n",
    "\n",
    "for idx in range(n_methods):\n",
    "    if methods_traj_x[idx].shape[1] == local_K:\n",
    "        axarr[idx, 0].plot(methods_traj_x[idx],  **pltstyle_h_mu)  # in this case, we are plotting the hidden/memory variables directly\n",
    "    else:\n",
    "        axarr[idx, 0].plot(methods_traj_x[idx][:, :local_N] @ params[1] / local_N,  **pltstyle)\n",
    "        if methods_traj_x[idx].shape[1] == (local_N + local_K):\n",
    "            # also plot hidden dim directly...\n",
    "            cc = [line_obj.get_c() for line_obj in axarr[idx, 0].get_lines()]\n",
    "            axarr[idx, 0].set_prop_cycle('color', cc)\n",
    "            axarr[idx, 0].plot(methods_traj_x[idx][:, :local_N] @ params[1] / local_N,  **pltstyle_h_mu)\n",
    "    axarr[idx, 0].set_title('HN classic quadratic %s' % methods_str[idx])\n",
    "    axarr[idx, 0].axhline(0, linestyle='--', linewidth=2, c='k')\n",
    "    \n",
    "    dxdt_arr = methods_foo[idx](0, methods_traj_x[idx].T, params)\n",
    "    axarr[idx, 1].plot(np.linalg.norm(dxdt_arr, axis=0),  **pltstyle)\n",
    "    axarr[idx, 1].set_title('Norm of $dx/dt$ for %s' % methods_str[idx])\n",
    "    axarr[idx, 1].axhline(0, linestyle='--', linewidth=2, c='k')\n",
    "    \n",
    "axarr[-1, 0].set_xlabel('t')\n",
    "axarr[-1, 1].set_xlabel('t')\n",
    "plt.suptitle('Example: HN classic quadratic\\n' + r'Trajectory $N^{-1} \\xi^T x(t)$ from IC perturbed from $\\xi^{(0)}$ (N=%d, K=%d)' % (local_N, local_K))\n",
    "plt.savefig(NB_OUTPUT + os.sep + 'HN-traj_near_xi0.pdf')\n",
    "plt.show(); plt.close('all')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a745db10fccaa291"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Now let's implement the modern Hopfield network vector field  \n",
    "$dx/dt = ...$"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "afc34d8493499e46"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Note: keep signature of function fixed for now as x, t, p - state [dim N], times [scalar], params [dim p]\n",
    "# TODO jit all func, or torch for eventual Autodiff\n",
    "\n",
    "def dxdt_mhn_A(t, x, params):\n",
    "    \"\"\"\n",
    "    # Throw a ball in R^2\n",
    "    # Three params: vx0, vy0, gravity\n",
    "    \"\"\"\n",
    "    vx0, vy0, g = params\n",
    "    dxdt = vx0\n",
    "    dydt = vy0 - g*t\n",
    "    return np.array([dxdt, dydt])\n",
    "\n",
    "# sample call\n",
    "dxdt_mhn_A(0, [10,10], [1, 1, 9.8])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2b0378075f2aaa0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "x0 = np.array([10,100])\n",
    "params = [1, 10, 9.8]\n",
    "x_traj, times_traj = run_traj(dxdt_particle, x0, params, t0=0.0, tmax=2, dt_max=0.1)'''"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9ec87c08dd7195a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''fig, axarr = plt.subplots(2, 1, sharex=True)\n",
    "pltstyle = dict(linestyle='--', marker='o')\n",
    "axarr[0].plot(times_traj, x_traj[:,0], **pltstyle); axarr[0].set_title('x vs t') \n",
    "axarr[1].plot(times_traj, x_traj[:,1], **pltstyle); axarr[1].set_title('y vs t')\n",
    "plt.suptitle('Simple example: launch particle with gravity - euler method')\n",
    "plt.show(); plt.close('all')'''"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cdffa5470e894131"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6a835c51c357b3cd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "py310celltypes",
   "language": "python",
   "display_name": "Python 3.10 (celltypes)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
